name: Scrape Hotels - Batched

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of cities per batch'
        required: false
        default: '2'
      max_concurrent:
        description: 'Max concurrent scrapers'
        required: false
        default: '1'

jobs:
  calculate-batches:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      - id: set-matrix
        run: |
          TOTAL_CITIES=$(wc -l < cities_top200.txt)
          BATCH_SIZE=${{ github.event.inputs.batch_size || '2' }}
          echo "TOTAL_CITIES: $TOTAL_CITIES"
          echo "BATCH_SIZE: $BATCH_SIZE"
          BATCHES=()
          for ((i=0; i<$TOTAL_CITIES; i+=$BATCH_SIZE)); do
            BATCHES+=("{\"start\": $i, \"size\": $BATCH_SIZE}")
          done
          MATRIX="{\"batch\": [$(IFS=,; echo "${BATCHES[*]}")]}"
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "DEBUG MATRIX: $MATRIX"
      # This prints out the matrix so you can see if it's empty
      - run: echo "Matrix is: ${{ steps.set-matrix.outputs.matrix }}"

  scrape-batch:
    needs: calculate-batches
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.calculate-batches.outputs.matrix) }}
      max-parallel: 1
      fail-fast: false
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraper for batch
        env:
          MAX_CONCURRENT: ${{ github.event.inputs.max_concurrent || '1' }}
        run: |
          echo "Processing batch: start=${{ matrix.batch.start }}, size=${{ matrix.batch.size }}"
          python aa_hotels_scraper.py
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: results-batch-${{ matrix.batch.start }}
          path: |
            cheapest_10k_hotels_by_city.csv

  combine-results:
    needs: scrape-batch
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install pandas
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results
      - name: Combine results
        run: |
          python - << 'EOF'
          import pandas as pd
          import glob
          csv_files = glob.glob('results/*/cheapest_10k_hotels_by_city.csv')
          if not csv_files:
              print("No results found!")
              exit(1)
          dfs = [pd.read_csv(f) for f in csv_files]
          combined = pd.concat(dfs, ignore_index=True)
          combined = combined.drop_duplicates(subset=['City'], keep='first')
          combined = combined.sort_values('Cost per Point')
          combined.to_csv('final_cheapest_10k_hotels.csv', index=False)
          EOF
      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: final-results-${{ github.run_number }}
          path: final_cheapest_10k_hotels.csv
