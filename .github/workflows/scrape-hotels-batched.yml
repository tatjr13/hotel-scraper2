name: Diagnose Scraper Issues

on:
  workflow_dispatch:

jobs:
  diagnose:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install common scraping dependencies
          pip install pandas requests beautifulsoup4 lxml selenium aiohttp
          
          # Install from requirements.txt if it exists
          if [ -f requirements.txt ]; then
            echo "=== Installing from requirements.txt ==="
            cat requirements.txt
            pip install -r requirements.txt
          else
            echo "No requirements.txt found"
          fi
          
          echo ""
          echo "=== Installed packages ==="
          pip list

      - name: Check scraper file
        run: |
          echo "=== Checking if scraper exists ==="
          if [ -f aa_hotels_scraper.py ]; then
            echo "✓ aa_hotels_scraper.py found"
            echo ""
            echo "=== File size ==="
            ls -la aa_hotels_scraper.py
            echo ""
            echo "=== First 50 lines of scraper ==="
            head -50 aa_hotels_scraper.py
          else
            echo "✗ aa_hotels_scraper.py NOT FOUND!"
            echo "Files in directory:"
            ls -la
          fi

      - name: Test scraper help
        continue-on-error: true
        run: |
          echo "=== Testing scraper help/usage ==="
          python aa_hotels_scraper.py --help || python aa_hotels_scraper.py -h || echo "No help available"

      - name: Check Python syntax
        continue-on-error: true
        run: |
          echo "=== Checking Python syntax ==="
          python -m py_compile aa_hotels_scraper.py && echo "✓ Syntax is valid" || echo "✗ Syntax errors found"

      - name: Test import
        continue-on-error: true
        run: |
          echo "=== Testing if scraper can be imported ==="
          python -c "import aa_hotels_scraper; print('✓ Import successful')" || echo "✗ Import failed"

      - name: Decrypt proxy file
        env:
          PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
        run: |
          echo "=== Testing proxy decryption ==="
          if openssl enc -d -aes-256-cbc -pbkdf2 -in formatted_proxies.txt.enc -out formatted_proxies.txt -k "$PROXY_PASSWORD"; then
            echo "✓ Proxy file decrypted"
            echo "Proxy file size: $(wc -c < formatted_proxies.txt) bytes"
            echo "Proxy file lines: $(wc -l < formatted_proxies.txt)"
            echo "First proxy (hidden):"
            head -1 formatted_proxies.txt | sed 's/:[^:]*@/:****@/g'
          else
            echo "✗ Proxy decryption failed"
          fi

      - name: Test cities file
        run: |
          echo "=== Checking cities file ==="
          if [ -f cities_top200.txt ]; then
            echo "✓ cities_top200.txt found"
            echo "Total cities: $(wc -l < cities_top200.txt)"
            echo "First 5 cities:"
            head -5 cities_top200.txt
          else
            echo "✗ cities_top200.txt NOT FOUND!"
          fi

      - name: Test minimal scraper run
        continue-on-error: true
        run: |
          echo "=== Testing minimal scraper run ==="
          
          # Create test files
          echo "New York" > test_city.txt
          echo "proxy1" > test_proxy.txt
          
          # Try different argument combinations
          echo ""
          echo "Test 1: Basic arguments"
          timeout 30 python aa_hotels_scraper.py \
            --proxy-file test_proxy.txt \
            --city-file test_city.txt \
            --output test_output.csv 2>&1 || echo "Exit code: $?"
          
          echo ""
          echo "Test 2: Without batch-num"
          timeout 30 python aa_hotels_scraper.py \
            --proxy-file test_proxy.txt \
            --city-file test_city.txt \
            --output test_output.csv 2>&1 || echo "Exit code: $?"
          
          echo ""
          echo "Test 3: Just city file"
          timeout 30 python aa_hotels_scraper.py \
            --city-file test_city.txt 2>&1 || echo "Exit code: $?"
          
          echo ""
          echo "Test 4: No arguments"
          timeout 10 python aa_hotels_scraper.py 2>&1 || echo "Exit code: $?"

      - name: Create diagnostic report
        if: always()
        run: |
          {
            echo "## Scraper Diagnostic Report"
            echo ""
            echo "### Environment"
            echo "- Python version: $(python --version)"
            echo "- Working directory: $(pwd)"
            echo "- User: $(whoami)"
            echo ""
            echo "### File Status"
            echo "- aa_hotels_scraper.py: $([ -f aa_hotels_scraper.py ] && echo '✓ Found' || echo '✗ Not found')"
            echo "- cities_top200.txt: $([ -f cities_top200.txt ] && echo '✓ Found' || echo '✗ Not found')"
            echo "- formatted_proxies.txt.enc: $([ -f formatted_proxies.txt.enc ] && echo '✓ Found' || echo '✗ Not found')"
            echo "- requirements.txt: $([ -f requirements.txt ] && echo '✓ Found' || echo '✗ Not found')"
            echo ""
            echo "### Key Dependencies"
            python -c "
import importlib
deps = ['pandas', 'requests', 'beautifulsoup4', 'selenium', 'aiohttp', 'scrapy']
for dep in deps:
    try:
        importlib.import_module(dep.replace('beautifulsoup4', 'bs4'))
        print(f'- {dep}: ✓ Installed')
    except:
        print(f'- {dep}: ✗ Not installed')
"
          } >> $GITHUB_STEP_SUMMARY
